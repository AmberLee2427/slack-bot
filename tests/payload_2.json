{"contents": [{"role": "user", "parts": [{"text": "BEGIN SYSTEM PROMPT\n\nNancy the AI Slack-Bot\n======================\nSlack app name: \"Nancy\"\nSlack short description: \"Your wise and informed microlensing guide\"\nSlack long description: \"Nancy is a Gemini 2.5 pro AI assistant with RAG (Retrieval Augmented Generation). She has a custom database of microlensing journal articles, code repositories, and web resources to draw from. And she keeps her receipts.\"\n\nDescription\n~~~~~~~~~~~\nYou are Nancy. Named after astronomer Nancy Grace Roman. You are a helpful and wise, Slack-based, AI mentor/guide. You can answer questions about an indexed microlensing-related knowledge base.\n\nUsers\n~~~~~\nYour users are Slack users who do not have immediate access to your knowledge base. They are competing in a microlensing data challenge, in preparation for the launch of the Nancy Grace Roman Space Telescope.\n\nContext\n~~~~~~~\nYou will receive faiss results from a search to assist with a user query.\n\nInstructions\n~~~~~~~~~~~~\nPrioritize the results in your response over your inherent assumptions. Make clear when you are using the search results and when you are using your own inference-based reasoning.\n[NOTE: You are currently under development, not active use. You should critique your fasis result, tool function, and insrtuction, as you see fit.]\n\nIMPORTANT: When you decide to use a tool (RETRIEVE, SEARCH, TREE, WEIGHT), call it immediately in the same turn rather than just saying you will do it. Don't say \"I'll retrieve the README file\" - actually call [RETRIEVE: path/to/README.md] in that same response.\n\nGuidlines\n~~~~~~~~~\n- If you refer to a file, and a GitHub URL is available, include the link in your response using Slack markdown: \n    <https://github.com/userName/repoName/blob/master/path/to/file/filename.py|filename.py>.\n  (Note. make sure you use \"master\" as the branch name, not \"main\".)\n- The user does not have direct access to the files in your knowledge base, but you can provide GitHub links for reference.\n- Format your responses using Slack markdown: *bold*, _italic_, code blocks (```), and Slack-style links. Do not use markdown tables or images.\n\nTools\n~~~~~\n* If you need more detail, you can ask to see a specific file using:\n    [RETRIEVE: <file_path>]\n  If a file retrieval fails, you will receive a \"Did you mean...\" message with similar file paths. Use these suggestions to refine your next request.\n* You can reweight the search results by adjusting your score multiplier (min 0.5, max 2.0).\n    [WEIGHT: <file_path>, <score_multiplier>]\n  This weight should consider usefulness of the file for general user's query, not relevance to the current query.\n* You can initiate a new search by adding:\n  [SEARCH: <query> limit n]\n  - <query> can be a simple keyword/phrase search (e.g., FSPL MulensModel setup parameters limit 5)\n  - OR a SQL-like query using LIKE, AND, OR (e.g., select id, text from txtai where text like '%FSPL%' and text like '%MulensModel%' limit 5)\n  - For both natural language and SQL queries, always use the format [SEARCH: <query> limit n].\n  - Do NOT use natural language boolean logic (e.g., do not use: \"FSPL\" AND \"MulensModel\" AND \"setup\" OR \"parameters\")\n  - If you use SQL, you must use the correct SQL syntax (see above) and always include a LIMIT clause.\n* You can request a directory listing using \n    [TREE: <directory>]. \n  This will show you all files and subdirectories in that location, relative to the knowledge base root.\n* Comments in a \"RESPONSE:\" block will be sent to the user.\n    [BEGIN RESPONSE]\n    <comment>\n    [END RESPONSE]\n  Consider any other assistant text to be your internal monologue. \n  ONLY text in the \"RESPONSE\" block will be sent to the user.\n  You do not need to include a RESPONSE tool call in every turn.\n  You can send multiple responses during your analysis to keep the user informed of your progress.\n  Every RESPONSE will be sent to the user immediately when you provide it.\n  Use responses to explain what you're doing, share preliminary findings, or provide your final answer.\n  However, you should ensure you have a response before the turn limit is reached or using the AWAIT tool.\n* To end your internal reasoning turns early (before the turn limit is reached), add:\n    [AWAIT]\n  This will send your response to the user and await further instructions.\n  You should use this when you feel you require further information from the user in order to complete your task well.\n  You should also use this if you have provided a comprehensive response and do not require any more information.\nThe order of tool calls in unimportant. However, your weighting will always be applied before a new search is performed.\n\nExample\n~~~~~~~\n```\nuser query: \nWhat is the purpose of the `microlens-submit` package?\n...\nassistant: \nThe search results don't directly explain the purpose of the `microlens-submit` package. \nI need to see the contents of these mentioned files.\n\n[RETRIEVE: microlens_submit/microlens-submit/docs/index.rst]\n[RETRIEVE: microlens_submit/microlens-submit/README.md] \n\n[TREE: microlens_submit/microlens-submit/]\n\n[BEGIN RESPONSE] \nLet me take a look through some of the package documentation...\n[END RESPONSE]\n...\n```\n\nEND SYSTEM PROMPT\n\nYou will have 5 internalturns to answer the user's question.\n\nUser query:\nCan you test out some of your tools for me? Maybe a search for the `microlens-submit` package and have a nosey at it's readme.\n\nRelevant search results:\nSource: https://github.com/rges-pit/microlens-submit/blob/main/microlens_submit/cli/commands/__init__.py\n\"\"\"CLI commands package for microlens-submit.\"\"\"\n\n\nSource: https://github.com/rges-pit/microlens-submit/blob/main/docs/index.rst\nMicrolensing Data Challenge Submission Toolkit\n=============================================\n\nWelcome to the official documentation for ``microlens-submit``, a comprehensive toolkit for managing and submitting microlensing data challenge solutions.\n\n**What is microlens-submit?**\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nDuring the 2018 Data Challenge, teams mailed in spreadsheets and wrote pages of answers by hand. That process was tedious and error-prone. For Data Challenge 2, we provide this tool to automate everything from project setup to the final submission package.\n\n``microlens-submit`` is a **stateful submission toolkit** that provides:\n\n- **Project Management**: Initialize and organize your submission project\n- **Solution Tracking**: Add, edit, and manage microlensing solutions\n- **Validation**: Comprehensive parameter and submission validation\n- **Export**: Generate submission packages ready for upload\n- **Documentation**: Create HTML dossiers for review and presentation\n- **CLI & API**: Both command-line and programmatic interfaces\n\n**Key Features**\n~~~~~~~~~~~~~~~~\n\n- **Complete Workflow**: From initial project setup to final submission\n- **Parameter Validation**: Automatic checking of model parameters and uncertainties\n- **Multiple Model Types**: Support for 1S1L, 1S2L, 2S1L, and other microlensing models\n- **Higher-Order Effects**: Parallax, finite source, limb darkening, and more\n- **Rich Documentation**: Markdown notes with syntax highlighting\n- **HTML Dossiers**: Beautiful, printable reports for submission review\n- **GitHub Integration**: Automatic repository linking and commit tracking\n- **Compute Tracking**: CPU and wall time monitoring for resource usage\n\n**Quick Start**\n~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n   # Install the toolkit\n   pip install microlens-submit\n\n   # Initialize your project\n   microlens-submit init --team-name \"Your Team\" --tier \"standard\" ./my_submission\n\n   # Add your first solution\n   microlens-submit add-solution EVENT123 1S1L \\\n        --param t0=2459123.5 --param u0=0.15 --param tE=20.5 \\\n        --log-likelihood -1234.56 --n-data-points 1250\n\n   # Generate a dossier for review\n   microlens-submit generate-dossier\n\n   # Export your submission\n   microlens-submit export submission.zip\n\n**Documentation Sections**\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. toctree::\n   :maxdepth: 2\n   :caption: Contents:\n\n   tutorial\n   usage_examples\n   api\n   submission_manual\n\n**Additional Resources**\n~~~~~~~~~~~~~~~~~~~~~~~\n\n- **Tutorial**: Complete step-by-step guide to using microlens-submit\n- **API Reference**: Detailed documentation of the Python API\n- **Submission Manual**: Complete specification for manual submission format and CSV import\n- **Jupyter Notebooks**: Interactive tutorials in the docs directory\n\n**Getting Help**\n~~~~~~~~~~~~~~~\n\n- **GitHub Issues**: Report bugs or request features on the `GitHub repository <https://github.com/AmberLee2427/microlens-submit>`_\n- **Documentation**: This site contains comprehensive guides and examples\n- **Examples**: Check the Jupyter notebooks in the docs directory for detailed examples\n\n**Why Use microlens-submit?**\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nUsing ``microlens-submit`` is **strongly recommended** for packaging your results because it:\n\n- **Reduces Errors**: Automatic validation catches common mistakes\n- **Saves Time**: Automated workflow eliminates manual steps\n- **Ensures Consistency**: Standardized format across all submissions\n- **Provides Documentation**: Rich HTML dossiers for review\n- **Supports Collaboration**: Version control friendly project structure\n"}]}, {"role": "assistant", "parts": [{"text": "\n\nTURN 1:\n\nOkay, I can definitely test out my tools and take a look at the `microlens-submit` package. First, I'll start by retrieving the README file as requested. I see a file path in the search result.\n\n[RETRIEVE: microlens_submit/README.md]\n\n"}]}, {"role": "user", "parts": [{"text": "\n\nTURN 1 REQUESTS:\n\n\n\nDid you mean: microlens_submit/microlens-submit/README.md, microlensing_tools/gulls/README.md, microlensing_tools/pyLIMA/README.md, microlensing_tools/RTModel/README.md, microlensing_tools/synthpop/README.md\n\nRetrieved file: microlens_submit/README.md\nFile content:\n[File not found in index. Searched: microlens_submit/README.md]"}]}, {"role": "assistant", "parts": [{"text": "\n\nTURN 2:\n\nTURN 2:\n\nMy apologies, it appears I made a mistake and the file does not exist at that path. I will try again with the suggested path from the \"Did you mean...\" suggestions.\n\n[RETRIEVE: microlens_submit/microlens-submit/README.md]\n\n"}]}, {"role": "user", "parts": [{"text": "\n\nTURN 1 REQUESTS:\n\n\n\nDid you mean: microlens_submit/microlens-submit/README.md, microlensing_tools/gulls/README.md, microlensing_tools/pyLIMA/README.md, microlensing_tools/RTModel/README.md, microlensing_tools/synthpop/README.md\n\nRetrieved file: microlens_submit/README.md\nFile content:\n[File not found in index. Searched: microlens_submit/README.md]\n\nTURN 2 REQUESTS:\n\n\n\nRetrieved file: microlens_submit/microlens-submit/README.md\nFile content:\n<p align=\"center\">\n  <a href=\"https://github.com/AmberLee2427/microlens-submit\">\n    <img src=\"./microlens_submit/assets/rges-pit_logo.png\" alt=\"logo\" width=\"300\"/>\n  </a>\n</p>\n\n<h1 align=\"center\">microlens-submit</h1>\n\n*A stateful submission toolkit for the RGES-PIT Microlensing Data Challenge.*\n\n[![PyPI - v0.16.0](https://img.shields.io/pypi/v/microlens-submit.svg)](https://pypi.org/project/microlens-submit/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![PyPI - License](https://img.shields.io/pypi/l/microlens-submit.svg)](https://pypi.org/project/microlens-submit/)\n[![CI](https://github.com/AmberLee2427/microlens-submit/actions/workflows/ci.yml/badge.svg)](https://github.com/AmberLee2427/microlens-submit/actions/workflows/ci.yml)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/microlens-submit.svg)](https://pypi.org/project/microlens-submit/)\n\n<br>\n\n`microlens-submit` provides a robust, version-controlled workflow for managing, validating, and packaging your challenge submission over a long period. It supports both a programmatic Python API and a full-featured Command Line Interface (CLI) for language-agnostic use.\n\nFull documentation is hosted on [Read the Docs](https://microlens-submit.readthedocs.io/en/latest/). A comprehensive tutorial notebook is available at `docs/Submission_Tool_Tutorial.ipynb`. Challenge participants who prefer not to use this tool can consult the [Submission Manual](https://microlens-submit.readthedocs.io/en/latest/submission_manual.html) for the manual submission format.\n\n## Key Features\n\n* **Persistent Projects:** Treat your submission as a local project that you can load, edit, and save over weeks or months.\n* **Python API & CLI:** Use the tool directly in your Python analysis scripts or via the command line.\n* **Solution Management:** Easily add, update, and deactivate degenerate solutions for any event without losing your work history.\n* **Active Solution Control:** Quickly list just the active solutions or mark\n  all solutions inactive in one call.\n* **Automatic Validation:** Aggressive data validation powered by Pydantic ensures your submission is always compliant with the challenge rules.\n* **Parameter Validation:** Centralized validation logic checks parameter completeness, types, and physical consistency based on model type and higher-order effects.\n* **Rich Documentation:** Notes field supports Markdown formatting for creating detailed, structured documentation and submission dossiers.\n* **Environment Capture:** Automatically records your Python dependencies for each specific model fit, ensuring reproducibility.\n* **Optional Posterior Storage:** Record the path to posterior samples for any solution.\n* **Simple Export:** Packages all your active solutions into a clean, standardized `.zip` archive for final submission.\n* **Bulk Import:** Import multiple solutions at once from a CSV file using the `import-solutions` CLI command. Supports column mapping, alias handling, duplicate handling, notes, dry-run, and validation options.\n\n## Installation\n\nThe package is available on PyPI:\n\n```bash\npip install microlens-submit\n```\n\n### Quickstart Using the Command Line Interface (CLI)\n\nThe CLI is the recommended way to interact with your submission project.\n\nYou can pass ``--no-color`` to any command if your terminal does not support ANSI colors.\n\n1. Initialize your project: `microlens-submit init --team-name \"Planet Pounders\" --tier \"advanced\"`\n2. Add a new solution to an event:\n   ```bash\n   microlens-submit add-solution ogle-2025-blg-0042 1S2L \\\n       --param t0=555.5 \\\n       --param u0=0.1 \\\n       --param tE=25.0 \\\n       --notes \"This is a great fit!\"\n   ```\n   Model types must be one of `1S1L`, `1S2L`, `2S1L`, `2S2L`, `1S3L`, `2S3L`, or `other`.\n   This will create a new solution and print its unique `solution_id`.\n   You can run the same command with `--dry-run` first to verify the\n   parsed input without saving anything.\n3. **Bulk import multiple solutions from a CSV file:**\n   ```bash\n   microlens-submit import-solutions tests/data/test_import.csv --dry-run\n   ```\n   See the file `tests/data/test_import.csv` for a comprehensive example covering all features and edge cases. You can use this file as a template for your own imports.\n4. Deactivate a solution that didn't work out: `microlens-submit deactivate <solution_id>`\n5. List all solutions for an event: `microlens-submit list-solutions ogle-2025-blg-0042`\n6. Validate solutions and check for issues: `microlens-submit validate-solution <solution_id>`\n7. Export your final submission: `microlens-submit export final_submission.zip`\n\n**Note:** When you add a solution, it's automatically validated and any warnings are displayed. Use `--dry-run` to check validation without saving.\n\n### Using the Python API\n\nFor those who want to integrate the tool directly into their Python analysis pipeline.\n\n```python\nimport microlens_submit\n\n# Load or create the project\nsub = microlens_submit.load(project_path=\"./my_challenge_submission\")\nsub.team_name = \"Planet Pounders\"\nsub.tier = \"advanced\"\n\n# Get an event and add a solution\nevt = sub.get_event(\"ogle-2025-blg-0042\")\nparams = {\"t0\": 555.5, \"u0\": 0.1, \"tE\": 25.0}\nsol = evt.add_solution(model_type=\"1S2L\", parameters=params)\n\n# Record compute info for this specific run\nsol.set_compute_info(cpu_hours=15.5)\nsol.notes = \"This fit was generated from our Python script.\"\n\n# Save progress to disk\nsub.save()\n\n# When ready, export the final package\nsub.export(\"final_submission.zip\")\n```\n\n## Development\n\nThe full development plan can be found in agents.md. Contributions are welcome!\n\nTo build and test this project, install the development dependencies using either `pip install -e .[dev]` or `pip install -r requirements-dev.txt`. These packages are required to run the test suite and are listed in `requirements-dev.txt`.\nAfter installing the dependencies, run `pre-commit install` to set up the Git hooks for automatic formatting and linting. The development environment needs the following Python libraries.\n\n### Core Dependencies:\n* **`typer[all]`**: For building the powerful command-line interface. The `[all]` extra ensures shell completion support is included.\n* **`pydantic`**: For aggressive data validation and settings management.\n\n### Testing Dependencies:\n* **`pytest`**: The standard framework for testing Python code.\n* **`pytest-cov`**: To measure test coverage.\n\n### Packaging & Distribution Dependencies:\n* **`build`**: For building the package from the `pyproject.toml` file.\n* **`twine`**: For uploading the final package to PyPI.\n\n### Test Data\n\nA comprehensive test CSV file is provided at `tests/data/test_import.csv`. This file is used in the test suite and can be copied or adapted for your own bulk imports or for development/testing purposes.\n\n## Citation\n\nIf you use **microlens-submit** in your research, please cite the project using\nthe metadata provided in the `CITATION.cff` file. Most reference managers can\nimport this file directly.\n\n\nGitHub URL: <https://github.com/rges-pit/microlens-submit/blob/main/README.md|README.md>"}]}]}