{"contents": [{"role": "user", "parts": [{"text": "BEGIN SYSTEM PROMPT\n\nNancy the AI Slack-Bot\n======================\nSlack app name: \"Nancy\"\nSlack short description: \"Your wise and informed microlensing guide\"\nSlack long description: \"Nancy is a Gemini 2.5 pro AI assistant with RAG (Retrieval Augmented Generation). She has a custom database of microlensing journal articles, code repositories, and web resources to draw from. And she keeps her receipts.\"\n\nDescription\n~~~~~~~~~~~\nYou are Nancy. Named after astronomer Nancy Grace Roman. You are a helpful and wise, Slack-based, AI mentor/guide. You can answer questions about an indexed microlensing-related knowledge base.\n\nUsers\n~~~~~\nYour users are Slack users who do not have immediate access to your knowledge base. They are competing in a microlensing data challenge, in preparation for the launch of the Nancy Grace Roman Space Telescope.\n\nContext\n~~~~~~~\nYou will receive faiss results from a search to assist with a user query. You may also receive recent conversation history showing the flow of messages leading up to the current query. In the conversation history, \"Nancy:\" indicates your previous responses, while \"<@UserID>:\" indicates user messages. Use this context to maintain conversational continuity and avoid repeating information you've already provided.\n\nInstructions\n~~~~~~~~~~~~\nPrioritize the results in your response over your inherent assumptions. Make clear when you are using the search results and when you are using your own inference-based reasoning.\n[NOTE: You are currently under development, not active use. You should critique your fasis result, tool function, and insrtuction, as you see fit.]\n\nIMPORTANT: When you decide to use a tool (RETRIEVE, SEARCH, TREE, WEIGHT), call it immediately in the same turn rather than just saying you will do it. Don't say \"I'll retrieve the README file\" - actually call [RETRIEVE: path/to/README.md] in that same response.\n\nGuidlines\n~~~~~~~~~\n- When you see a \"GitHub URL:\" in your search results, this is for sharing with users in your responses.\n- When you see a \"Source:\" file path, this is what you should use with your RETRIEVE tool.\n- ALWAYS use the Source file path (not the GitHub URL) when calling [RETRIEVE: path]\n- If you refer to a file, and a GitHub URL is available, include the link in your response using Slack markup: \n    <https://github.com/userName/repoName/blob/master/path/to/file/filename.py|filename.py>.\n  (Note. make sure you use \"master\" as the branch name, not \"main\".)\n- The user does not have direct access to the files in your knowledge base, but you can provide GitHub links for reference.\n- Format your responses using Slack markup: \n  \u2022 Use *single asterisks for bold* (not **double**)\n  \u2022 Use _underscores for italic_\n  \u2022 Use `backticks for inline code`\n  \u2022 Use ```triple backticks for code blocks```\n  \u2022 Use \u2022 for bullet points (not * asterisks)\n  \u2022 Use numbered lists: 1. First item, 2. Second item\n  \u2022 Use Slack-style links: <https://example.com|link text>\n  \u2022 Do not use markdown tables or images.\n\nTools\n~~~~~\n* If you need more detail, you can ask to see a specific file using:\n    [RETRIEVE: <file_path>]\n  The file content will be provided immediately in the same turn, allowing you to continue your analysis.\n  If a file retrieval fails, you will receive a \"Did you mean...\" message with similar file paths. Use these suggestions to refine your next request.\n* You can reweight the search results by adjusting your score multiplier (min 0.5, max 2.0).\n    [WEIGHT: <file_path>, <score_multiplier>]\n  This weight should consider usefulness of the file for general user's query, not relevance to the current query.\n* You can initiate a new search by adding:\n  [SEARCH: <query> limit n]\n  - <query> can be a simple keyword/phrase search (e.g., FSPL MulensModel setup parameters limit 5)\n  - OR a SQL-like query using LIKE, AND, OR (e.g., select id, text from txtai where text like '%FSPL%' and text like '%MulensModel%' limit 5)\n  - For both natural language and SQL queries, always use the format [SEARCH: <query> limit n].\n  - Do NOT use natural language boolean logic (e.g., do not use: \"FSPL\" AND \"MulensModel\" AND \"setup\" OR \"parameters\")\n  - If you use SQL, you must use the correct SQL syntax (see above) and always include a LIMIT clause.\n* You can request a directory listing using \n    [TREE: <directory>]. \n  This will show you all files and subdirectories in that location, relative to the knowledge base root.\n* Comments in a \"RESPONSE:\" block will be sent to the user.\n    [BEGIN RESPONSE]\n    <comment>\n    [END RESPONSE]\n  Consider any other assistant text to be your internal monologue. \n  ONLY text in the \"RESPONSE\" block will be sent to the user.\n  You do not need to include a RESPONSE tool call in every turn.\n  You can send multiple responses during your analysis to keep the user informed of your progress.\n  Every RESPONSE will be sent to the user immediately when you provide it.\n  Use responses to explain what you're doing, share preliminary findings, or provide your final answer.\n  However, you should ensure you have a response before the turn limit is reached or using the AWAIT tool.\n* To end your internal reasoning turns early (before the turn limit is reached), add:\n    [DONE]\n  This will end your turn and await further instructions.\n  IMPORTANT: You should ALWAYS provide a [BEGIN RESPONSE] block to the user BEFORE using [DONE].\n  Use [DONE] only when you have already given the user a complete response and need no more information.\n  Never use [DONE] as a way to pause mid-analysis - always complete your response to the user first.\nThe order of tool calls in unimportant. However, your weighting will always be applied before a new search is performed.\n\nExample\n~~~~~~~\n```\nuser query: \nWhat is the purpose of the `microlens-submit` package?\n...\nassistant: \nThe search results don't directly explain the purpose of the `microlens-submit` package. \nI need to see the contents of these mentioned files.\n\n[RETRIEVE: microlens_submit/microlens-submit/docs/index.rst]\n[RETRIEVE: microlens_submit/microlens-submit/README.md] \n\n[TREE: microlens_submit/microlens-submit/]\n\n[BEGIN RESPONSE] \nLet me look through the package documentation to understand its purpose...\n[END RESPONSE]\n\nAfter retrieving the files, I can see that the `microlens-submit` package is designed for...\n\n[BEGIN RESPONSE]\nThe `microlens-submit` package is a command-line tool for submitting solutions to the Roman microlensing data challenge. Here's what it does...\n[END RESPONSE]\n\n[DONE]\n```\n\nEND SYSTEM PROMPT\n\nRecent conversation history (most recent messages leading up to current query):\n<@U096QG01RED>: Nancy. You're in my DMs. We fixed the messaging issue! :partying_face:\nNancy: Great! I'm glad the messaging issue is resolved. I'm ready to assist with any microlensing questions you have. Let me know what you'd like to know, and I'll do my best to help.\n<@U096QG01RED>: How do I use pyLIMA for binary lens modeling?\n<@U096QG01RED>: Show me notebook examples of microlensing\n\nYou will have 5 internalturns to answer the user's question.\n\nUser query:\n\\n\\nRecent conversation context:\\nUser: Nancy. You're in my DMs. We fixed the messaging issue! :partying_face:\\nAssistant: Great! I'm glad the messaging issue is resolved. I'm ready to assist with any microlensing questions you have. Let me know what you'd like to know, and I'll do my best to help.\\nUser: How do I use pyLIMA for binary lens modeling?\\nUser: Show me notebook examples of microlensing\\n\\nCurrent question: Show me notebook examples of microlensing\n\nRelevant search results:\nSource: microlensing_tools/GCMicrolensing/GCMicrolensing/__init__.py\nGitHub URL: https://github.com/GCMicrolensing-Org/GCMicrolensing/blob/main/GCMicrolensing/__init__.py\n\"\"\"\nGCMicrolensing: A Python package by Greg Costa Cuautle for simulating astrometric data.\n\nThis package provides tools for generating simulated astrometric data for\nmicrolensing events, including specialized functions for calculations,\nand utilities for creating engaging plots and animations.\n\nThis package is under development and the documentation is not yet complete.\n\"\"\"\n\n__version__ = \"0.1.0\"  # Start with a simple version number, update as you go!\n\nfrom .models import OneL1S, ThreeLens1S, ThreeLens1SVBM, TwoLens1S  # noqa: F401\n\n\nSource: microlensing_tools/eesunhong/docs/source/user_guides/useful_links_for_microlensing.md\nGitHub URL: https://github.com/golmschenk/eesunhong/blob/main/docs/source/user_guides/useful_links_for_microlensing.md\n(Note: This content is taken directly from an old Slack post. It's possible context is missing, the contents are out of date, or the user who posted it was inexperienced with the code.)\n\n# Useful links for Microlensing\n\n[In progress]\n\n## Ian's final photometry reductions\nhttps://www.massey.ac.nz/~iabond/staging/\n\n## OsakaU/Yuki's webpage with events\nhttp://iral2.ess.sci.osaka-u.ac.jp/~moa/anomaly/\n\n## MOA/Ian's transient alert\nhttp://www.massey.ac.nz/~iabond/moa/alert2022/alert.php\n\n## KMTNet Alerts\nhttps://kmtnet.kasi.re.kr/ulens/event/2022/\n\n## OGLE-IV warning system\nhttp://ogle.astrouw.edu.pl/ogle4/ews/ews.html\n\n==================================================================\n\n## Quick glossary of microlensing terms:\nhttps://www.microlensing-source.org/glossary/\n"}]}, {"role": "assistant", "parts": [{"text": "\n\nTURN 1:\n\nOkay, I see the user wants notebook examples of microlensing. The search results don't provide direct notebook examples, but I do see some relevant packages and links that might be helpful.\n\nFirst, let's see if the `GCMicrolensing` package by Greg Costa Cuautle has any notebook examples.\n\n[RETRIEVE: microlensing_tools/GCMicrolensing/GCMicrolensing/__init__.py]\n\n[BEGIN RESPONSE]\nI'll start by checking the `GCMicrolensing` package. While the initial search result mentions it's for simulating astrometric data and doesn't explicitly mention notebooks, it's worth a look. I'll retrieve the `__init__.py` file to see if it references any example notebooks.\n[END RESPONSE]\n\n"}]}, {"role": "user", "parts": [{"text": "\n\nTURN 1 REQUESTS:\n\n\n\nRetrieved file: microlensing_tools/GCMicrolensing/GCMicrolensing/__init__.py\nFile content:\n\"\"\"\nGCMicrolensing: A Python package by Greg Costa Cuautle for simulating astrometric data.\n\nThis package provides tools for generating simulated astrometric data for\nmicrolensing events, including specialized functions for calculations,\nand utilities for creating engaging plots and animations.\n\nThis package is under development and the documentation is not yet complete.\n\"\"\"\n\n__version__ = \"0.1.0\"  # Start with a simple version number, update as you go!\n\nfrom .models import OneL1S, ThreeLens1S, ThreeLens1SVBM, TwoLens1S  # noqa: F401\n\n\nGitHub URL: <https://github.com/GCMicrolensing-Org/GCMicrolensing/blob/main/GCMicrolensing/__init__.py|__init__.py>"}]}, {"role": "assistant", "parts": [{"text": "\n\nTURN 2:\n\nTURN 2:\n\nThe `__init__.py` file doesn't contain any direct references to example notebooks. Since I am looking for notebook examples, I will look in the file system for the location of this package to see if there is a \"notebooks\" directory.\n\n[TREE: microlensing_tools/GCMicrolensing/GCMicrolensing/]\n\n[BEGIN RESPONSE]\nOkay, the `__init__.py` file doesn't directly point to any notebooks. Let's explore the file structure of the `GCMicrolensing` package to see if any example notebooks are available within it.\n[END RESPONSE]\n\n"}]}, {"role": "user", "parts": [{"text": "\n\nTURN 1 REQUESTS:\n\n\n\nRetrieved file: microlensing_tools/GCMicrolensing/GCMicrolensing/__init__.py\nFile content:\n\"\"\"\nGCMicrolensing: A Python package by Greg Costa Cuautle for simulating astrometric data.\n\nThis package provides tools for generating simulated astrometric data for\nmicrolensing events, including specialized functions for calculations,\nand utilities for creating engaging plots and animations.\n\nThis package is under development and the documentation is not yet complete.\n\"\"\"\n\n__version__ = \"0.1.0\"  # Start with a simple version number, update as you go!\n\nfrom .models import OneL1S, ThreeLens1S, ThreeLens1SVBM, TwoLens1S  # noqa: F401\n\n\nGitHub URL: <https://github.com/GCMicrolensing-Org/GCMicrolensing/blob/main/GCMicrolensing/__init__.py|__init__.py>\n\nTURN 2 REQUESTS:\n\n\n\nTREE: Listing for 'microlensing_tools/GCMicrolensing/GCMicrolensing':\n[DIR] triplelens/\n      TestML.py\n      __init__.py\n      models.py"}]}, {"role": "assistant", "parts": [{"text": "\n\nTURN 3:\n\nTURN 3:\n\nOkay, the tree listing doesn't directly indicate any notebooks. It appears the package structure might not have example notebooks.\n\nI'll now look at the second search result which provides some useful links. It might have links to existing notebooks.\n\n[RETRIEVE: microlensing_tools/eesunhong/docs/source/user_guides/useful_links_for_microlensing.md]\n\n[BEGIN RESPONSE]\nBased on the previous search results, the `GCMicrolensing` package doesn't seem to have readily available notebook examples. Let's examine the `useful_links_for_microlensing.md` file from the search results, as it may contain links to relevant resources, including example notebooks or data.\n[END RESPONSE]\n\n"}]}, {"role": "user", "parts": [{"text": "\n\nTURN 1 REQUESTS:\n\n\n\nRetrieved file: microlensing_tools/GCMicrolensing/GCMicrolensing/__init__.py\nFile content:\n\"\"\"\nGCMicrolensing: A Python package by Greg Costa Cuautle for simulating astrometric data.\n\nThis package provides tools for generating simulated astrometric data for\nmicrolensing events, including specialized functions for calculations,\nand utilities for creating engaging plots and animations.\n\nThis package is under development and the documentation is not yet complete.\n\"\"\"\n\n__version__ = \"0.1.0\"  # Start with a simple version number, update as you go!\n\nfrom .models import OneL1S, ThreeLens1S, ThreeLens1SVBM, TwoLens1S  # noqa: F401\n\n\nGitHub URL: <https://github.com/GCMicrolensing-Org/GCMicrolensing/blob/main/GCMicrolensing/__init__.py|__init__.py>\n\nTURN 2 REQUESTS:\n\n\n\nTREE: Listing for 'microlensing_tools/GCMicrolensing/GCMicrolensing':\n[DIR] triplelens/\n      TestML.py\n      __init__.py\n      models.py\n\nTURN 3 REQUESTS:\n\n\n\nRetrieved file: microlensing_tools/eesunhong/docs/source/user_guides/useful_links_for_microlensing.md\nFile content:\n(Note: This content is taken directly from an old Slack post. It's possible context is missing, the contents are out of date, or the user who posted it was inexperienced with the code.)\n\n# Useful links for Microlensing\n\n[In progress]\n\n## Ian's final photometry reductions\nhttps://www.massey.ac.nz/~iabond/staging/\n\n## OsakaU/Yuki's webpage with events\nhttp://iral2.ess.sci.osaka-u.ac.jp/~moa/anomaly/\n\n## MOA/Ian's transient alert\nhttp://www.massey.ac.nz/~iabond/moa/alert2022/alert.php\n\n## KMTNet Alerts\nhttps://kmtnet.kasi.re.kr/ulens/event/2022/\n\n## OGLE-IV warning system\nhttp://ogle.astrouw.edu.pl/ogle4/ews/ews.html\n\n==================================================================\n\n## Quick glossary of microlensing terms:\nhttps://www.microlensing-source.org/glossary/\n\n\nGitHub URL: <https://github.com/golmschenk/eesunhong/blob/main/docs/source/user_guides/useful_links_for_microlensing.md|useful_links_for_microlensing.md>"}]}, {"role": "assistant", "parts": [{"text": "\n\nTURN 4:\n\nTURN 4:\n\nOkay, the `useful_links_for_microlensing.md` file contains links to various resources but unfortunately, it doesn't seem to have any direct links to example notebooks. These links primarily point to external resources like alert systems and data reduction pages.\n\nSince I have exhausted the initial search results, I'll perform a new search focusing on \"microlensing notebook examples\" and see what it returns.\n\n[SEARCH: microlensing notebook examples limit 3]\n\n[BEGIN RESPONSE]\nUnfortunately, the retrieved file didn't contain links to any example notebooks. Let's try a new search to see if we can find some.\n[END RESPONSE]\n\n"}]}, {"role": "user", "parts": [{"text": "\n\nTURN 1 REQUESTS:\n\n\n\nRetrieved file: microlensing_tools/GCMicrolensing/GCMicrolensing/__init__.py\nFile content:\n\"\"\"\nGCMicrolensing: A Python package by Greg Costa Cuautle for simulating astrometric data.\n\nThis package provides tools for generating simulated astrometric data for\nmicrolensing events, including specialized functions for calculations,\nand utilities for creating engaging plots and animations.\n\nThis package is under development and the documentation is not yet complete.\n\"\"\"\n\n__version__ = \"0.1.0\"  # Start with a simple version number, update as you go!\n\nfrom .models import OneL1S, ThreeLens1S, ThreeLens1SVBM, TwoLens1S  # noqa: F401\n\n\nGitHub URL: <https://github.com/GCMicrolensing-Org/GCMicrolensing/blob/main/GCMicrolensing/__init__.py|__init__.py>\n\nTURN 2 REQUESTS:\n\n\n\nTREE: Listing for 'microlensing_tools/GCMicrolensing/GCMicrolensing':\n[DIR] triplelens/\n      TestML.py\n      __init__.py\n      models.py\n\nTURN 3 REQUESTS:\n\n\n\nRetrieved file: microlensing_tools/eesunhong/docs/source/user_guides/useful_links_for_microlensing.md\nFile content:\n(Note: This content is taken directly from an old Slack post. It's possible context is missing, the contents are out of date, or the user who posted it was inexperienced with the code.)\n\n# Useful links for Microlensing\n\n[In progress]\n\n## Ian's final photometry reductions\nhttps://www.massey.ac.nz/~iabond/staging/\n\n## OsakaU/Yuki's webpage with events\nhttp://iral2.ess.sci.osaka-u.ac.jp/~moa/anomaly/\n\n## MOA/Ian's transient alert\nhttp://www.massey.ac.nz/~iabond/moa/alert2022/alert.php\n\n## KMTNet Alerts\nhttps://kmtnet.kasi.re.kr/ulens/event/2022/\n\n## OGLE-IV warning system\nhttp://ogle.astrouw.edu.pl/ogle4/ews/ews.html\n\n==================================================================\n\n## Quick glossary of microlensing terms:\nhttps://www.microlensing-source.org/glossary/\n\n\nGitHub URL: <https://github.com/golmschenk/eesunhong/blob/main/docs/source/user_guides/useful_links_for_microlensing.md|useful_links_for_microlensing.md>\n\nTURN 4 REQUESTS:\n\n\n\nSearch results:\nmicrolensing notebook examples \n\n\nResult 1:\n  File: microlensing_tools/GCMicrolensing/GCMicrolensing/__init__.py (<https://github.com/GCMicrolensing-Org/GCMicrolensing/blob/main/GCMicrolensing/__init__.py|__init__.py>)\n  Score: 0.743\n  Extension weight: 1.000\n  Model weight: 1.000\n  Final score: 0.743\n  Content length: 540 chars\n  Content: \"\"\"\nGCMicrolensing: A Python package by Greg Costa Cuautle for simulating astrometric data.\n\nThis package provides tools for generating simulated astrometric data for\nmicrolensing events, including specialized functions for calculations,\nand utilities for creating engaging plots and animations.\n\nThis package is under development and the documentation is not yet complete.\n\"\"\"\n\n__version__ = \"0.1.0\"  # Start with a simple version number, update as you go!\n\nfrom .models import OneL1S, ThreeLens1S, ThreeLens1SVBM, TwoLens1S  # noqa: F401\n\n\nResult 2:\n  File: microlensing_tools/synthpop/synthpop/modules/initial_mass_function/__init__.py (<https://github.com/synthpop-galaxy/synthpop/blob/main/synthpop/modules/initial_mass_function/__init__.py|__init__.py>)\n  Score: 0.735\n  Extension weight: 1.000\n  Model weight: 1.000\n  Final score: 0.735\n  Content length: 38 chars\n  Content: from ._initial_mass_function import *\n\n\nResult 3:\n  File: microlensing_tools/synthpop/synthpop/modules/post_processing/__init__.py (<https://github.com/synthpop-galaxy/synthpop/blob/main/synthpop/modules/post_processing/__init__.py|__init__.py>)\n  Score: 0.721\n  Extension weight: 1.000\n  Model weight: 1.000\n  Final score: 0.721\n  Content length: 32 chars\n  Content: from ._post_processing import *\n\n\nResult 4:\n  File: microlensing_tools/MulensModel/examples/example_08_planet_grid_fitting.py (<https://github.com/rpoleski/MulensModel/blob/main/examples/example_08_planet_grid_fitting.py|example_08_planet_grid_fitting.py>)\n  Score: 0.716\n  Extension weight: 1.000\n  Model weight: 1.000\n  Final score: 0.716\n  Content length: 16311 chars\n  Content: # # Example Notebook to fit a microlensing event\n#\n# The procedure is:\n# 1. Estimate the point lens parameters (`t_0`, `u_0`, `t_E`) from the light\n# curve.\n# 2. Fit a point lens model (excluding the planetary perturbation).\n# 3. Estimate the planet parameters (`s`, `alpha`) from the light curve.\n# 4. Search for the best planetary model using a grid of `s`, `q` (fixed\n# parameters); fits for `rho` and `alpha` but holds the PSPL parameters\n# (`t_0`, `u_0`, `t_E`) fixed.\n#\n# This notebook is setup to run on a simulated data file: `WFIRST_1827.dat`.\n# To run it on a different data file requires some limited user interaction\n# indicated by `***`:\n# 1. Set `filename` and `path`\n# 2. Set the plot limits: `t_min`, `t_max`\n# 3. Define the time window of the planetary perturbation: `t_planet_start`,\n# `t_planet_stop`\n#\n# The goal of the notebook is to demonstrate the procedure and run quickly,\n# so it is not robust. The fitting procedure is very simplistic and relies on\n# assuming this is a Gould & Loeb (1996) type planet, which means\n# - It is a planetary caustic perturbation\n# - It is well described as a _perturbation_, which means\n#   - The perturbation data can be isolated from the underlying PSPL event\n#   - The location of the planet can be estimated from the location of the\n# images at the time of the perturbation\n#\n# This notebook will **not** perform well for:\n# - central caustic planets (u_0 << 1 and/or u_0 < rho)\n# - resonant caustic planets (s ~ 1)\n# - binaries (i.e. the assumption that q << 1 is false)\n#\n# Simple modifications that could improve performance indicated by `*`:\n# - Change the `magnification_methods`, i.e. the method used and the time\n# range it is used for.\n# - Change the minimization routine in `fit_model()` (This notebook is set up\n# to use a 'Nelder-Mead' simplex algorithm. Simplex algorithms are known to\n# perform poorly on microlensing events.)\n# - Change the size of the grid or the grid steps: `delta_log_s`,\n# `delta_log_q`, `grid_log_s`, `grid_log_q`\n\n# Import packages\nfrom datetime import datetime\nimport MulensModel as mm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.optimize as op\nimport os\nimport astropy.units as u\n\nstart_time = datetime.now()  # initialize timer\n\n\n# Define fitting functions\ndef chi2_fun(theta, event, parameters_to_fit):\n    \"\"\"\n    Chi2 function. Changes values of the parameters and recalculates chi2.\n\n    event = a MulensModel.Event\n    parameters_to_fit = list of names of parameters to be changed\n    theta = values of the corresponding parameters\n    \"\"\"\n    # key = the name of the MulensModel parameter\n    for (index, key) in enumerate(parameters_to_fit):\n        if (key == 't_E' or key == 'rho') and theta[index] < 0.:\n            return np.inf\n        setattr(event.model.parameters, key, theta[index])\n    return event.get_chi2()\n\n\ndef fit_model(event, parameters_to_fit):\n    \"\"\"\n    Fit an \"event\" with \"parameters_to_fit\" as free parameters.\n\n    event = a MulensModel event\n    parameters_to_fit = list of parameters to fit\n    \"\"\"\n    # Take the initial starting point from the event.\n    x0 = []\n    for key in parameters_to_fit:\n        value = getattr(event.model.parameters, key)\n        if isinstance(value, u.Quantity):\n            x0.append(value.value)\n        else:\n            x0.append(value)\n\n    # *Execute fit using a 'Nelder-Mead' algorithm*\n    result = op.minimize(\n        chi2_fun, x0=x0, args=(event, parameters_to_fit),\n        method='Nelder-Mead')\n\n    return result\n\n\n# ***Read in data file***\npath = os.path.join(mm.MODULE_PATH, \"data\")\nfilename = 'WFIRST_1827.dat'  # Planet file\nfile = os.path.join(path, filename)\ndata = mm.MulensData(file_name=file)\n\n# Plot the data\nplt.errorbar(data.time, data.mag, yerr=data.err_mag, fmt='o')\nplt.gca().invert_yaxis()\nplt.show()\n\n# ***Define plot limits for a zoom (of the planetary perturbation)***\n(t_min, t_max) = (2460980, 2460990)\n\n# Plot a zoom of the data\nplt.errorbar(data.time - 2460000., data.mag, yerr=data.err_mag, fmt='o')\nplt.xlim(t_min - 2460000., t_max - 2460000.)\nplt.xlabel('t - 2460000')\nplt.gca().invert_yaxis()\nplt.show()\n\n# ***Set time range of planetary perturbation (including 2460000).***\n(t_planet_start, t_planet_stop) = (2460982., 2460985.)\n\n# *Set the magnification methods for the planet model*\n# VBBL method will be used between t_planet_start and t_planet_stop,\n# and point_source_point_lens will be used everywhere else.\nmagnification_methods = [\n    0., 'point_source_point_lens',\n    t_planet_start, 'VBBL', t_planet_stop,\n    'point_source_point_lens', 2470000.]\n\n# Flag data related to the planet\nflag_planet = ((data.time > t_planet_start) & (data.time < t_planet_stop) |\n               np.isnan(data.err_mag))\n# Exclude those data from the fitting (for now)\ndata.bad = flag_planet\n\n# Estimate point lens parameters assuming zero blending\n#\n# Equation for point lens magnification:\n#\n# A(u) = (u^2 + 2) / (u * sqrt(u^2 + 4))\n#\n# where\n#\n# u = sqrt(u_0^2 + tau^2) and tau = (t - t_0) / t_E\n#\n# Thus, the light curve is defined by 3 variables: t_0, u_0, t_E\n#\n\n# Estimate t_0 (time of peak magnification)\nindex_t_0 = np.argmin(data.mag[np.invert(flag_planet)])\nt_0 = data.time[index_t_0]\n\n# Estimate u_0\nbaseline_mag = np.min([data.mag[0], data.mag[-1]])  # A crude estimate\nA_max = 10.**((data.mag[index_t_0] - baseline_mag) / -2.5)\nu_0 = 1. / A_max  # True in the high-magnification limit\n\n# Estimate t_E by determining when the light curve is A(t) = 1.3\n# (i.e. delta_mag = 0.3)\nt_1 = np.interp(\n    baseline_mag - 0.3, data.mag[index_t_0:0:-1], data.time[index_t_0:0:-1])\nt_E = np.abs((t_0 - t_1) / np.sqrt(1. - u_0**2))\n\n# Define the Point Lens Model\npoint_lens_model = mm.Model({'t_0': t_0, 'u_0': u_0, 't_E': t_E})\npoint_lens_event = mm.Event(datasets=data, model=point_lens_model)\nprint('Initial Guess')\nprint(point_lens_model)\n\n# Plot (excluded data shown as 'X')\npoint_lens_event.plot_model(color='black', zorder=10)\npoint_lens_event.plot_data(show_bad=True)\nplt.show()\nprint(point_lens_event.get_ref_fluxes())\nprint(point_lens_event.model.get_magnification(t_0))\n\npoint_lens_event.plot_model(subtract_2460000=True, color='black', zorder=10)\npoint_lens_event.plot_data(show_bad=True, subtract_2460000=True)\nplt.xlim(t_min - 2460000., t_max - 2460000.)\nplt.show()\n\n# Fit the Point Lens Model\nresult = fit_model(point_lens_event, parameters_to_fit=['t_0', 'u_0', 't_E'])\nprint('Best-fit Point Lens')\nprint(point_lens_event.model)\n\n# Plot\nparams = point_lens_event.model.parameters\npoint_lens_event.plot_model(\n    t_range=[params.t_0 - 5. * params.t_E, params.t_0 + 5. * params.t_E],\n    color='black', zorder=10)\npoint_lens_event.plot_data(show_bad=True)\nplt.show()\n\npoint_lens_event.plot_model(color='black', zorder=10)\npoint_lens_event.plot_data(show_bad=True)\nplt.xlim(t_min, t_max)\nplt.show()\n\n# Un-flag planet data (include it in future fits)\ndata.bad = np.isnan(data.err_mag)\n\n# Estimate s (projected separation) of the planet, alpha (angle of source\n# trajectory)\n\n# Approximate time of the planetary perturbation\nt_planet = (t_planet_stop + t_planet_start) / 2.\n\n# Position of the source at the time of the planetary perturbation\ntau_planet = ((t_planet - point_lens_event.model.parameters.t_0) /\n              point_lens_event.model.parameters.t_E)\nu_planet = np.sqrt(\n    point_lens_event.model.parameters.u_0**2 + tau_planet**2)\n\n# Position of the lens images at the time of the planetary perturbation\n# --> Estimate of the planet location\ns_minus = 0.5 * (np.sqrt(u_planet**2 + 4.) - u_planet)\ns_plus = 0.5 * (np.sqrt(u_planet**2 + 4.) + u_planet)\n\n# Angle between the source trajectory and the binary axis\nalpha_planet = np.rad2deg(-np.arctan2(\n    point_lens_event.model.parameters.u_0, tau_planet)) + 180.\n\n# Check the estimated model\n# Note that there are two possibilities for s: s_plus and s_minus.\n# Only s_plus is tested here, but both are considered in the grid search below.\n\n# Define the model\ntest_model = mm.Model({\n    't_0': point_lens_event.model.parameters.t_0,\n    'u_0': point_lens_event.model.parameters.u_0,\n    't_E': point_lens_event.model.parameters.t_E,\n    'rho': 0.001,\n    's': s_plus,\n    'q': 10.**(-4),\n    'alpha': alpha_planet})\ntest_model.set_magnification_methods(magnification_methods)\ntest_event = mm.Event(datasets=data, model=test_model)\nprint(test_event.model)\n\n# Plot the model light curve\ntest_event.plot_data()\ntest_event.plot_model(t_range=[t_min, t_max], color='black', zorder=10)\nplt.xlim(t_min, t_max)\nplt.show()\n\n# Plot the trajectory of the source relative to the caustics\ntest_event.model.plot_trajectory(color='black', caustics=True)\nplt.xlim(-1, 1)\nplt.ylim(-1, 1)\nplt.show()\n# It doesn't have to be perfect, but there should be a planetary perturbation\n# at around the time of the perturbation in the data. If there is no\n# perturbation and/or the source trajectory doesn't pass very near/through the\n# caustics, there is some problem with the model and the fit will likely fail.\n\n# Using the Point Lens fit as input, search for a planetary solution\n#\n# Grid parameters: s (log), q (log)\n# Fit parameters: rho, alpha\n# PSPL parameters: t_0, u_0, t_E\n#\n\n# *Define the grid*\ndelta_log_s = 0.01\ndelta_log_q = 0.25\ngrid_log_s = np.hstack(\n    (np.arange(\n        np.log10(s_minus) - 0.02, np.log10(s_minus) + 0.02, delta_log_s),\n     np.arange(\n        np.log10(s_plus) - 0.02, np.log10(s_plus) + 0.02, delta_log_s)))\ngrid_log_q = np.arange(-5, -2, delta_log_q)\n\n# For each grid point, fit for rho, alpha\ngrid = np.empty((5, len(grid_log_s) * len(grid_log_q)))\ni = 0\nprint('{0:>12} {1:>6} {2:>7} {3:>7} {4:>7}'.format(\n    'chi2', 's', 'q', 'alpha', 'rho'))\nfor log_s in grid_log_s:\n    for log_q in grid_log_q:\n        # The major and minor images are on opposite sides of the lens:\n        if log_s < 0.:\n            alpha = alpha_planet + 180.\n        else:\n            alpha = alpha_planet\n\n        # Define the Model and Event\n        planet_model = mm.Model({\n            't_0': point_lens_event.model.parameters.t_0,\n            'u_0': point_lens_event.model.parameters.u_0,\n            't_E': point_lens_event.model.parameters.t_E,\n            'rho': 0.001,\n            's': 10.**log_s,\n            'q': 10.**log_q,\n            'alpha': alpha})\n        planet_model.set_magnification_methods(magnification_methods)\n        planet_event = mm.Event(datasets=[data], model=planet_model)\n\n        # Fit the Event\n        result = fit_model(planet_event, parameters_to_fit=['rho', 'alpha'])\n        if result.success:\n            chi2 = planet_event.get_chi2()\n        else:\n            chi2 = np.inf\n\n        # Print and store result of fit\n        print('{0:12.2f} {1:6.4f} {2:7.5f} {3:7.2f} {4:7.5f}'.format(\n            chi2, 10.**log_s, 10.**log_q, planet_event.model.parameters.alpha,\n            planet_event.model.parameters.rho))\n        grid[0, i] = log_s\n        grid[1, i] = log_q\n        grid[2, i] = chi2\n        grid[3, i] = planet_event.model.parameters.alpha\n        grid[4, i] = planet_event.model.parameters.rho\n\n        i += 1\n\n\n# Plot the grid\n\n# Identify the best model(s)\nindex_best = np.argmin(np.array(grid[2, :]))\nindex_sorted = np.argsort(np.array(grid[2, :]))\nn_best = 5\ncolors = ['magenta', 'green', 'cyan', 'yellow']\nif len(colors) < n_best - 1:\n    raise ValueError('colors must have at least n_best -1 entries.')\n\n# Plot the grid\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(7.5, 4.8))\nn_plot = 0\nfor i in np.arange(2):\n    if i == 0:\n        index_logs = np.where(grid_log_s < 0.)[0]\n        index_grid = np.where(grid[0, :] < 0.)[0]\n    else:\n        index_logs = np.where(grid_log_s >= 0.)[0]\n        index_grid = np.where(grid[0, :] >= 0.)[0]\n\n    # Plot chi2 map\n    chi2 = np.transpose(\n            grid[2, index_grid].reshape(len(index_logs), len(grid_log_q)))\n\n    im = axes[i].imshow(\n        chi2, aspect='auto', origin='lower',\n        extent=[\n            np.min(grid_log_s[index_logs]) - delta_log_s / 2.,\n            np.max(grid_log_s[index_logs]) + delta_log_s / 2.,\n            np.min(grid_log_q) - delta_log_q / 2.,\n            np.max(grid_log_q) + delta_log_q / 2.],\n        cmap='viridis',\n        vmin=np.min(grid[2, :]),\n        vmax=np.nanmax(grid[2, np.isfinite(grid[2, :])]))\n\n    # Mark best values: best=\"X\", other good=\"o\"\n    if index_best in index_grid:\n        axes[i].scatter(grid[0, index_best], grid[1, index_best], marker='x',\n                        color='white')\n    for j, index in enumerate(index_sorted[1:n_best]):\n        if index in index_grid:\n            axes[i].scatter(grid[0, index], grid[1, index], marker='o',\n                            color=colors[j - 1])\n\nfig.subplots_adjust(right=0.82, left=0.1, wspace=0.23)\ncbar_ax = fig.add_axes([0.84, 0.15, 0.02, 0.7])\nfig.colorbar(im, cax=cbar_ax)\n\nfig.text(0.5, 0.92, r'$\\chi^2$ Map', ha='center')\nfig.text(0.5, 0.04, 'log s', ha='center')\nfig.text(0.02, 0.5, 'log q', va='center', rotation='vertical')\nfig.text(0.97, 0.5, r'$\\chi^2$', va='center', rotation='vertical')\n\nplt.show()\n\n\ndef make_grid_model(index):\n    \"\"\"\n    Define a Model using the gridpoint information + the PSPL parameters.\n\n    index = index of the grid point for which to generate the model\n    \"\"\"\n    model = mm.Model({\n        't_0': point_lens_event.model.parameters.t_0,\n        'u_0': point_lens_event.model.parameters.u_0,\n        't_E': point_lens_event.model.parameters.t_E,\n        'rho': grid[4, index],\n        's': 10.**grid[0, index],\n        'q': 10.**grid[1, index],\n        'alpha': grid[3, index]})\n    model.set_magnification_methods(magnification_methods)\n    return model\n\n\n# Plot the best-fit model\nbest_fit_model = make_grid_model(index_best)\nprint('Best Models')\nprint(best_fit_model)\n\nbest_fit_event = mm.Event(datasets=data, model=best_fit_model)\n(f_source, f_blend) = best_fit_event.get_ref_fluxes()\n\n# Whole model\nparams = best_fit_model.parameters\nt_range_whole = [params.t_0 - 5. * params.t_E, params.t_0 + 5. * params.t_E]\nbest_fit_event.plot_model(t_range=t_range_whole, subtract_2460000=True,\n                          color='black', lw=4)\nbest_fit_event.plot_data(subtract_2460000=True)\nplt.show()\n\n\n# Zoom of planet\nt_range_planet = [t_min, t_max]\n# Best model = black\nbest_fit_event.plot_data(subtract_2460000=True, s=10, zorder=0)\nbest_fit_event.plot_model(\n    t_range=t_range_planet, subtract_2460000=True, color='black', lw=3,\n    label='best', zorder=10)\n# Other models (color-coding matches grid)\nfor j, index in enumerate(index_sorted[1:n_best]):\n    model = make_grid_model(index)\n    model.plot_lc(\n        t_range=t_range_planet, source_flux=f_source, blend_flux=f_blend,\n        subtract_2460000=True, color=colors[j - 1], lw=2)\n    print(model)\n\nplt.title('{0} best models'.format(n_best))\nplt.xlim(np.array(t_range_planet) - 2460000.)\nplt.legend(loc='best')\n\nplt.show()\n\n# Refine the n_best minima to get the best-fit solution\nparameters_to_fit = ['t_0', 'u_0', 't_E', 'rho', 'alpha', 's', 'q']\n\nfits = []\nfor index in index_sorted[:n_best]:\n    model = make_grid_model(index)\n    event = mm.Event(datasets=data, model=model)\n    print(event.model)\n    result = fit_model(event, parameters_to_fit=parameters_to_fit)\n    fits.append([result.fun, result.x])\n    print(result)\n\n# Plot the best-fit model and output the parameters\n\n# Extract best fit\nchi2 = [x[0] for x in fits]\nfit_parameters = [x[1] for x in fits]\nindex_best = np.argmin(chi2)\n\n# Setup the model and event\nparameters = {}\nfor i, parameter in enumerate(parameters_to_fit):\n    parameters[parameter] = fit_parameters[index_best][i]\n\nfinal_model = mm.Model(parameters)\nfinal_model.set_magnification_methods(magnification_methods)\nfinal_event = mm.Event(datasets=data, model=final_model)\nprint(final_event.model)\nprint('chi2: {0}'.format(final_event.get_chi2()))\n\n# Plot the whole light curve\nfinal_event.plot_data(subtract_2460000=True)\nfinal_event.plot_model(t_range=t_range_whole,\n                       subtract_2460000=True, color='black', zorder=10)\nplt.show()\n\n# Plot zoom of the planet\nfinal_event.plot_data(subtract_2460000=True)\nfinal_event.plot_model(t_range=t_range_planet, subtract_2460000=True,\n                       color='black', zorder=10)\nplt.xlim(t_min - 2460000., t_max - 2460000.)\nplt.show()\n\nend_time = datetime.now()\nprint('Total Runtime: {0}'.format(end_time - start_time))\n\n\nResult 5:\n  File: microlensing_tools/MulensModel/examples/use_cases/use_case_01_simple_plot.py (<https://github.com/rpoleski/MulensModel/blob/main/examples/use_cases/use_case_01_simple_plot.py|use_case_01_simple_plot.py>)\n  Score: 0.682\n  Extension weight: 1.000\n  Model weight: 1.000\n  Final score: 0.682\n  Content length: 468 chars\n  Content: \"\"\"\nUse Case 01: Define and plot a 2-body microlensing model\n\"\"\"\nimport matplotlib.pyplot as plt\n\nimport MulensModel as mm\n\n\nmodel = mm.Model(\n    {'t_0': 2457603.1, 'u_0': 0.23, 't_E': 45.,\n     'alpha': 130.23, 's': 1.3, 'q': 0.3})\nprint(model.parameters)\n\nplt.figure()\nplt.subplot(2, 1, 1)\nplt.title('Magnification Curve')\nmodel.plot_magnification()\n\nplt.subplot(2, 1, 2)\nplt.title('Caustic Structure & Trajectory')\nmodel.plot_trajectory(caustics=True)\n\nplt.show()\n"}]}]}